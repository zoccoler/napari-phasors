{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from napari_phasors._reader import *\n",
    "# from napari_phasors._reader import _get_filename_extension, _parse_and_call_io_function\n",
    "from natsort import natsorted\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"D:\\Datasets\\FLIM\\new_acquisition\\hazelnut_3D_FLIM.sptw\"\n",
    "path2 = r\"D:\\Datasets\\FLIM\\new_acquisition\\hazelnut_3D_FLIM_folder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(path).is_dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "flim-phasor-plotter-reader functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_tz(file_path):\n",
    "    \"\"\"Get current time point and z slice from file name.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : Path\n",
    "        A Path object from pathlib. It expects a file name with '_t' and '_z' patterns.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    current_t, current_z : Tuple(int, int)\n",
    "        Current time point and z slice.\n",
    "    \"\"\"\n",
    "    import re\n",
    "    pattern_t = '_t(\\\\d+)'\n",
    "    pattern_z = '_z(\\\\d+)'\n",
    "    current_t, current_z = None, None\n",
    "    file_name = file_path.stem\n",
    "    matches_z = re.search(pattern_z, file_name)\n",
    "    if matches_z is not None:\n",
    "        current_z = int(matches_z.group(1))\n",
    "        current_z -= 1 # 0-based index while file names convention are 1-based\n",
    "    matches_t = re.search(pattern_t, file_name)\n",
    "    if matches_t is not None:\n",
    "        current_t = int(matches_t.group(1))\n",
    "        current_t -= 1 # 0-based index while file names convention are 1-based\n",
    "    return current_t, current_z \n",
    "\n",
    "def get_max_zslices(file_paths, file_extension):\n",
    "    \"\"\"Get max z slices.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_paths : List of paths\n",
    "        A list of Path objects from pathlib.\n",
    "    file_extension : str\n",
    "        A file extension, like '.tif' or '.ptu'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    max_z : int\n",
    "        Max z slices.\n",
    "    \"\"\"\n",
    "    max_z = max([get_current_tz(file_path)\n",
    "                for file_path in file_paths if file_path.suffix == file_extension])[1]\n",
    "    if max_z is None:\n",
    "        return 0\n",
    "    return max_z\n",
    "\n",
    "\n",
    "def get_max_time_points(file_paths, file_extension):\n",
    "    \"\"\"Get max time points.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_paths : List of paths\n",
    "        A list of Path objects from pathlib.\n",
    "    file_extension : str\n",
    "        A file extension, like '.tif' or '.ptu'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    max_time : int\n",
    "        Max time points.\n",
    "    \"\"\"\n",
    "    max_time = max([get_current_tz(file_path)\n",
    "                   for file_path in file_paths if file_path.suffix == file_extension])[0]\n",
    "    if max_time is None:\n",
    "        return 0\n",
    "    return max_time\n",
    "\n",
    "def get_structured_list_of_paths(file_paths, file_extension):\n",
    "    \"\"\"Get structured list of paths.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_paths : List of paths\n",
    "        A list of Path objects from pathlib.\n",
    "    file_extension : str\n",
    "        A file extension, like '.tif' or '.ptu'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    t_path_list : List of lists of paths\n",
    "        A list of lists of Path objects from pathlib. The first list is the time points, the second list is the z slices.\n",
    "    \"\"\"\n",
    "    from natsort import natsorted\n",
    "    t_path_list = []\n",
    "    z_path_list = []\n",
    "    file_paths = natsorted(file_paths)\n",
    "    previous_t = 0\n",
    "    for file_path in file_paths:\n",
    "        if file_path.suffix == file_extension:\n",
    "            current_t, current_z = get_current_tz(file_path)\n",
    "            if current_t is not None:\n",
    "                if current_t > previous_t:\n",
    "                    t_path_list.append(z_path_list)\n",
    "                    z_path_list = []\n",
    "                    previous_t = current_t\n",
    "                z_path_list.append(file_path)\n",
    "    # If no timepoints, z_path_list is file_paths\n",
    "    if current_t is None:\n",
    "        z_path_list = file_paths\n",
    "    # Append last timepoint\n",
    "    t_path_list.append(z_path_list)\n",
    "    return t_path_list\n",
    "\n",
    "def get_most_frequent_file_extension(path):\n",
    "    \"\"\"Get most frequent file extension in path.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str or list of str\n",
    "        Path to file, or list of paths.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    most_frequent_file_type : str\n",
    "        Most frequent file extension in path.\n",
    "    \"\"\"\n",
    "    from pathlib import Path\n",
    "    # Check if path is a list of paths\n",
    "    if isinstance(path, list):\n",
    "        # reader plugins may be handed single path, or a list of paths.\n",
    "        # if it is a list, it is assumed to be an image stack...\n",
    "        # so we are going to look at the most common file extension/suffix.\n",
    "        suffixes = [Path(p).suffix for p in path]\n",
    "    # Path is a single string\n",
    "    else:\n",
    "        path = Path(path)\n",
    "        # If directory\n",
    "        if path.is_dir():\n",
    "            if path.suffix == '.zarr':\n",
    "                suffixes = ['.zarr']\n",
    "            # Check if directory has suffix (meaning it can be .zarr)\n",
    "            # if path.suffix != '':\n",
    "            #     # Get path suffix\n",
    "            #     suffixes = [path.suffix]\n",
    "            # Get suffixes from files inside\n",
    "            else:\n",
    "                suffixes = [p.suffix for p in path.iterdir()]\n",
    "        # Get file suffix\n",
    "        elif path.is_file():\n",
    "            suffixes = [path.suffix]\n",
    "    # Get most frequent file entension in path\n",
    "    most_frequent_file_type = max(set(suffixes), key=suffixes.count)\n",
    "    return most_frequent_file_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "napari-phasors reader functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This module contains functions to read files supported by `phasorpy.io`\n",
    "and computes phasor coordinates with `phasorpy.phasor.phasor_from_signal`\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import inspect\n",
    "import os\n",
    "from typing import Any, Callable, Optional, Sequence, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import phasorpy.io as io\n",
    "import tifffile\n",
    "from napari.layers import Labels\n",
    "from napari.utils.notifications import show_error\n",
    "from phasorpy.phasor import phasor_from_signal\n",
    "\n",
    "extension_mapping = {\n",
    "    \"raw\": {\n",
    "        \".ptu\": lambda path, reader_options: _parse_and_call_io_function(\n",
    "            path,\n",
    "            io.read_ptu,\n",
    "            {\"frame\": (-1, False), \"keepdims\": (True, False)},\n",
    "            reader_options,\n",
    "        ),\n",
    "        \".fbd\": lambda path, reader_options: _parse_and_call_io_function(\n",
    "            path,\n",
    "            io.read_fbd,\n",
    "            {\"frame\": (-1, False), \"keepdims\": (True, False)},\n",
    "            reader_options,\n",
    "        ),\n",
    "        \".sdt\": lambda path, reader_options: _parse_and_call_io_function(\n",
    "            path,\n",
    "            io.read_sdt,\n",
    "            {},\n",
    "            reader_options,\n",
    "        ),\n",
    "        \".lsm\": lambda path, reader_options: _parse_and_call_io_function(\n",
    "            path,\n",
    "            io.read_lsm,\n",
    "            {},\n",
    "            reader_options,\n",
    "        ),\n",
    "        \".tif\": lambda path, reader_options: _parse_and_call_io_function(\n",
    "            path,\n",
    "            tifffile.imread,\n",
    "            {},\n",
    "            reader_options,\n",
    "        ),\n",
    "        # \".flif\": lambda path: io.read_flif(path),\n",
    "        # \".bh\": lambda path: io.read_bh(path),\n",
    "        # \".bhz\": lambda path: io.read_bhz(path),\n",
    "        # \".ifli\": lambda path: io.read_ifli(),\n",
    "    },\n",
    "    \"processed\": {\n",
    "        \".ome.tif\": lambda path, reader_options: _parse_and_call_io_function(\n",
    "            path, io.phasor_from_ometiff, {}, reader_options\n",
    "        ),\n",
    "        # \".b64\": lambda path: io.read_b64(path),\n",
    "        # \".r64\": lambda path: io.read_r64(path),\n",
    "        # \".ref\": lambda path: io.read_ref(path)\n",
    "    },\n",
    "}\n",
    "\"\"\"This dictionary contains the mapping for reader functions from\n",
    "`phasorpy.io` supported formats.\n",
    "\n",
    "Commented file extensions are not supported at the moment.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "iter_index_mapping = {\n",
    "    \".ptu\": \"C\",\n",
    "    \".fbd\": \"C\",\n",
    "    \".lsm\": None,\n",
    "    \".tif\": None,\n",
    "    '.sdt': None,\n",
    "}\n",
    "\"\"\"This dictionary contains the mapping for the axis to iterate over\n",
    "when calculating phasor coordinates in the file.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def napari_get_reader(\n",
    "    path: str,\n",
    "    reader_options: Optional[dict] = None,\n",
    "    harmonics: Union[int, Sequence[int], None] = None,\n",
    ") -> Optional[Callable]:\n",
    "    \"\"\"Initial reader function to map file extension to\n",
    "    specific reader functions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Path to file.\n",
    "    reader_options : dict, optional\n",
    "        Dictionary containing the arguments to pass to the function.\n",
    "    harmonics : Union[int, Sequence[int], None], optional\n",
    "        Harmonic(s) to be processed. Can be a single integer, a sequence of\n",
    "        integers, or None. Default is None.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    layer_data : list of tuples, or None\n",
    "        A list of LayerData tuples where each tuple in the list contains a\n",
    "        napari.layers.Labels layer a tuple  (data, kwargs), where data is\n",
    "        the mean intensity image as an array, and kwargs is a a dict of\n",
    "        keyword arguments for the corresponding viewer.add_* method in napari,\n",
    "        which contains the 'name' of the layer as well as the 'metadata',\n",
    "        which is also a dict. The values for key 'phasor_features_labels_layer'\n",
    "        in 'metadata' contain phasor coordinates as columns 'G' and 'S'.\n",
    "\n",
    "    \"\"\"\n",
    "    # if Path(path).is_dir():\n",
    "\n",
    "    if path.endswith(tuple(extension_mapping[\"processed\"].keys())):\n",
    "        return lambda path: processed_file_reader(\n",
    "            path, reader_options=reader_options, harmonics=harmonics\n",
    "        )\n",
    "    elif path.endswith(tuple(extension_mapping[\"raw\"].keys())):\n",
    "        return lambda path: raw_file_reader(\n",
    "            path, reader_options=reader_options, harmonics=harmonics\n",
    "        )\n",
    "    else:\n",
    "        show_error(\"File extension not supported.\")\n",
    "\n",
    "\n",
    "def raw_file_reader(\n",
    "    path: str,\n",
    "    reader_options: Optional[dict] = None,\n",
    "    harmonics: Union[int, Sequence[int], None] = None,\n",
    ") -> list[tuple]:\n",
    "    \"\"\"Read raw data files from supported file formats and apply the phasor\n",
    "    transformation to get mean intensity image and phasor coordinates.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Path to file.\n",
    "    reader_options : dict, optional\n",
    "        Dictionary containing the arguments to pass to the function.\n",
    "    harmonics : Union[int, Sequence[int], None], optional\n",
    "        Harmonic(s) to be processed. Can be a single integer, a sequence of\n",
    "        integers, or None. Default is None.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    layer_data : list of tuples\n",
    "        A list of LayerData tuples where each tuple in the list contains a\n",
    "        napari.layers.Labels layer a tuple  (data, kwargs), where data is\n",
    "        the mean intensity image as an array, and kwargs is a a dict of\n",
    "        keyword arguments for the corresponding viewer.add_* method in napari,\n",
    "        which contains the 'name' of the layer as well as the 'metadata',\n",
    "        which is also a dict. The values for key 'phasor_features_labels_layer'\n",
    "        in 'metadata' contain phasor coordinates as columns 'G' and 'S'.\n",
    "\n",
    "    \"\"\"\n",
    "    filename, file_extension = _get_filename_extension(path)\n",
    "    raw_data = extension_mapping[\"raw\"][file_extension](path, reader_options)\n",
    "    layers = []\n",
    "    iter_axis = iter_index_mapping[file_extension]\n",
    "    if iter_axis is None:\n",
    "        if file_extension == \".tif\":\n",
    "            mean_intensity_image, G_image, S_image = phasor_from_signal(\n",
    "                raw_data, axis=0, harmonic=harmonics\n",
    "            )\n",
    "        elif file_extension == '.sdt':\n",
    "            mean_intensity_image, G_image, S_image = phasor_from_signal(\n",
    "                raw_data, axis=-1, harmonic=harmonics\n",
    "            )\n",
    "        else:\n",
    "            # Calculate phasor over channels if file is of hyperspectral type\n",
    "            mean_intensity_image, G_image, S_image = phasor_from_signal(\n",
    "                raw_data, axis=raw_data.dims.index(\"C\"), harmonic=harmonics\n",
    "            )\n",
    "        labels_layer = make_phasors_labels_layer(\n",
    "            mean_intensity_image,\n",
    "            G_image,\n",
    "            S_image,\n",
    "            name=filename,\n",
    "            harmonics=harmonics,\n",
    "        )\n",
    "        add_kwargs = {\n",
    "            \"name\": f\"{filename} Intensity Image\",\n",
    "            \"metadata\": {\n",
    "                \"phasor_features_labels_layer\": labels_layer,\n",
    "                \"original_mean\": mean_intensity_image,\n",
    "            },\n",
    "        }\n",
    "        layers.append((mean_intensity_image, add_kwargs))\n",
    "    else:\n",
    "        iter_axis_index = raw_data.dims.index(iter_axis)\n",
    "        for channel in range(raw_data.shape[iter_axis_index]):\n",
    "            # Calculate phasor over photon counts dimension if file is FLIM\n",
    "            mean_intensity_image, G_image, S_image = phasor_from_signal(\n",
    "                raw_data.sel(C=channel),\n",
    "                axis=raw_data.sel(C=channel).dims.index(\"H\"),\n",
    "                harmonic=harmonics,\n",
    "            )\n",
    "            labels_layer = make_phasors_labels_layer(\n",
    "                mean_intensity_image,\n",
    "                G_image,\n",
    "                S_image,\n",
    "                name=filename,\n",
    "                harmonics=harmonics,\n",
    "            )\n",
    "            add_kwargs = {\n",
    "                \"name\": f\"{filename} Intensity Image: Channel {channel}\",\n",
    "                \"metadata\": {\n",
    "                    \"phasor_features_labels_layer\": labels_layer,\n",
    "                    \"original_mean\": mean_intensity_image,\n",
    "                },\n",
    "            }\n",
    "            layers.append((mean_intensity_image, add_kwargs))\n",
    "    return layers\n",
    "\n",
    "\n",
    "def processed_file_reader(\n",
    "    path: str,\n",
    "    reader_options: Optional[dict[str, str]] = None,\n",
    "    harmonics: Union[int, Sequence[int], None] = None,\n",
    ") -> list[tuple]:\n",
    "    \"\"\"Reader function for files that contain processed images, as phasor\n",
    "    coordinates or intensity images.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Path to file.\n",
    "    reader_options : dict, optional\n",
    "        Dictionary containing the arguments to pass to the function.\n",
    "    harmonics : Union[int, Sequence[int], None], optional\n",
    "        Harmonic(s) to be processed. Can be a single integer, a sequence of\n",
    "        integers, or None. Default is None.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    layer_data : list of tuples\n",
    "        A list of LayerData tuples where each tuple in the list contains a\n",
    "        napari.layers.Labels layer a tuple  (data, kwargs), where data is\n",
    "        the mean intensity image as an array, and kwargs is a a dict of\n",
    "        keyword arguments for the corresponding viewer.add_* method in napari,\n",
    "        which contains the 'name' of the layer as well as the 'metadata',\n",
    "        which is also a dict. The values for key 'phasor_features_labels_layer'\n",
    "        in 'metadata' contain phasor coordinates as columns 'G' and 'S'.\n",
    "\n",
    "    \"\"\"\n",
    "    filename, file_extension = _get_filename_extension(path)\n",
    "    reader_options = reader_options or {'harmonic': harmonics}\n",
    "    mean_intensity_image, G_image, S_image, attrs = extension_mapping[\n",
    "        \"processed\"\n",
    "    ][file_extension](path, reader_options)\n",
    "    labels_layer = make_phasors_labels_layer(\n",
    "        mean_intensity_image,\n",
    "        G_image,\n",
    "        S_image,\n",
    "        name=filename,\n",
    "        harmonics=harmonics,\n",
    "    )\n",
    "    layers = []\n",
    "    add_kwargs = {\n",
    "        \"name\": filename + \" Intensity Image\",\n",
    "        \"metadata\": {\n",
    "            \"phasor_features_labels_layer\": labels_layer,\n",
    "            \"original_mean\": mean_intensity_image,\n",
    "            \"attrs\": attrs,\n",
    "        },\n",
    "    }\n",
    "    layers.append((mean_intensity_image, add_kwargs))\n",
    "    return layers\n",
    "\n",
    "\n",
    "def make_phasors_labels_layer(\n",
    "    mean_intensity_image: Any,\n",
    "    G_image: Any,\n",
    "    S_image: Any,\n",
    "    name: str = \"\",\n",
    "    harmonics: Union[int, Sequence[int], None] = None,\n",
    ") -> Labels:\n",
    "    \"\"\"Create a napari Labels layer from phasor coordinates.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mean_intensity_image : np.ndarray\n",
    "        Mean intensity image.\n",
    "    G_image : np.ndarray\n",
    "        G phasor coordinates.\n",
    "    S_image : np.ndarray\n",
    "        S phasor coordinates.\n",
    "    name : str, optional\n",
    "        Name of the layer, by default ''.\n",
    "    harmonics : Union[int, Sequence[int], None], optional\n",
    "        Harmonic(s) to be processed. Can be a single integer, a sequence of\n",
    "        integers, or None. Default is None.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    labels_layer : napari.layers.Labels\n",
    "        Labels layer with phasor coordinates as features.\n",
    "\n",
    "    \"\"\"\n",
    "    pixel_id = np.arange(1, mean_intensity_image.size + 1)\n",
    "    table = pd.DataFrame()\n",
    "    if len(G_image.shape) > 2:\n",
    "        for i in range(G_image.shape[0]):\n",
    "            harmonic_value = harmonics[i] if harmonics is not None else i + 1\n",
    "            sub_table = pd.DataFrame(\n",
    "                {\n",
    "                    \"label\": pixel_id,\n",
    "                    \"G_original\": G_image[i].ravel(),\n",
    "                    \"S_original\": S_image[i].ravel(),\n",
    "                    \"G\": G_image[i].ravel(),\n",
    "                    \"S\": S_image[i].ravel(),\n",
    "                    \"harmonic\": harmonic_value,\n",
    "                }\n",
    "            )\n",
    "            table = pd.concat([table, sub_table])\n",
    "    else:\n",
    "        if isinstance(harmonics, list):\n",
    "            harmonic_value = harmonics[0]\n",
    "        else:\n",
    "            harmonic_value = harmonics if harmonics is not None else 1\n",
    "        # Get pixel coordinates from G_image\n",
    "        table = pd.DataFrame(\n",
    "            {\n",
    "                \"label\": pixel_id,\n",
    "                \"G_original\": G_image.ravel(),\n",
    "                \"S_original\": S_image.ravel(),\n",
    "                \"G\": G_image.ravel(),\n",
    "                \"S\": S_image.ravel(),\n",
    "                \"harmonic\": harmonic_value,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    labels_data = pixel_id.reshape(mean_intensity_image.shape)\n",
    "    labels_layer = Labels(\n",
    "        labels_data,\n",
    "        name=f\"{name} Phasor Features Layer\",\n",
    "        scale=(1, 1),\n",
    "        features=table,\n",
    "    )\n",
    "    return labels_layer\n",
    "\n",
    "\n",
    "def _parse_and_call_io_function(\n",
    "    path: str,\n",
    "    func: Callable,\n",
    "    args_defaults: dict[str, Any],\n",
    "    reader_options: Optional[dict[str, Any]] = None,\n",
    ") -> Any:\n",
    "    \"\"\"Private helper function to parse arguments and call a `io` function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Path to file.\n",
    "    func : callable\n",
    "        Function to call.\n",
    "    args_defaults : dict\n",
    "        Dictionary containing the default arguments for the function.\n",
    "    reader_options : dict, optional\n",
    "        Dictionary containing the arguments to pass to the function.\n",
    "        Default is None.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : xarray.DataArray\n",
    "        Data read from the file\n",
    "\n",
    "    \"\"\"\n",
    "    args = {}\n",
    "    # Use reader_options if provided, otherwise use the default\n",
    "    if reader_options is not None:\n",
    "        for arg, value in reader_options.items():\n",
    "            args[arg] = value\n",
    "\n",
    "    # Fill in defaults for any missing arguments not provided in reader_options\n",
    "    for arg, (default, is_required) in args_defaults.items():\n",
    "        if arg not in args:\n",
    "            if is_required:\n",
    "                raise ValueError(f\"Required argument '{arg}' is missing.\")\n",
    "            args[arg] = default\n",
    "\n",
    "    # Validate arguments against the function's signature\n",
    "    valid_args = {}\n",
    "    sig = inspect.signature(func)\n",
    "    for arg, value in args.items():\n",
    "        if arg in sig.parameters:\n",
    "            valid_args[arg] = value\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Invalid argument '{arg}' for function {func.__name__}.\"\n",
    "            )\n",
    "    return func(path, **valid_args)\n",
    "\n",
    "\n",
    "def _get_filename_extension(path: str) -> tuple[str, str]:\n",
    "    \"\"\"Get the filename and extension from a path.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Path to file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    filename : str\n",
    "        Filename.\n",
    "    file_extension : str\n",
    "        File extension including the leading dot.\n",
    "\n",
    "    \"\"\"\n",
    "    filename = os.path.basename(path)\n",
    "    parts = filename.split(\".\", 1)\n",
    "    if len(parts) > 1:\n",
    "        file_extension = \".\" + parts[1]\n",
    "    else:\n",
    "        file_extension = \"\"\n",
    "    return parts[0], file_extension.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Datasets\\\\FLIM\\\\new_acquisition\\\\hazelnut_3D_FLIM.sptw'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is dir\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading stack: 100%|██████████| 63/63 [00:58<00:00,  1.08slices/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "harmonics = [1, 2]\n",
    "reader_options = None\n",
    "if Path(path).is_dir():\n",
    "    print('is dir')\n",
    "    folder_path = Path(path)\n",
    "    # Get most common file extension inside folder (unless \"folder\" is a \".zarr\" file)\n",
    "    file_extension = get_most_frequent_file_extension(folder_path)\n",
    "    if file_extension == '.zarr':\n",
    "        show_error(f\"File extension {file_extension} not supported.\")\n",
    "    else:\n",
    "        # Get all file paths inside folder with the most common file extension\n",
    "        file_paths = natsorted([file_path for file_path in folder_path.iterdir(\n",
    "        ) if file_path.suffix == file_extension])\n",
    "        # Get max time points and z slices based on file names convention (\"_z\" and \"_t\" patterns)\n",
    "        list_of_time_point_paths = get_structured_list_of_paths(\n",
    "                file_paths, file_extension)\n",
    "        # Set up progress bar\n",
    "        progress_bar = tqdm(total=len(list_of_time_point_paths) * len(list_of_time_point_paths[0]),\n",
    "                        desc='Reading stack', unit='slices')\n",
    "\n",
    "        z_list, t_list, z_list_labels = [], [], []\n",
    "        max_label = 0\n",
    "        built_labels = False\n",
    "        for list_of_zslice_paths in list_of_time_point_paths:\n",
    "            for zslice_path in list_of_zslice_paths:\n",
    "                # Read file (z-slice) based on file extension\n",
    "                if zslice_path.suffix in (tuple(extension_mapping[\"processed\"].keys())):\n",
    "                    layer_data_tuple = processed_file_reader(\n",
    "                        path=zslice_path, reader_options=reader_options, harmonics=harmonics\n",
    "                    )\n",
    "                elif zslice_path.suffix in (tuple(extension_mapping[\"raw\"].keys())):\n",
    "                    layer_data_tuple = raw_file_reader(\n",
    "                        path=zslice_path, reader_options=reader_options, harmonics=harmonics\n",
    "                    )\n",
    "                else:\n",
    "                    show_error(\"File extension not supported.\")\n",
    "\n",
    "                z_slice_image = np.squeeze(layer_data_tuple[0][0])\n",
    "                if built_labels is False:\n",
    "                    # Store labels z-slice array\n",
    "                    z_slice_labels = np.squeeze(layer_data_tuple[0][1]['metadata']['phasor_features_labels_layer'].data) + max_label\n",
    "                    max_label = z_slice_labels.max()\n",
    "                    z_list_labels.append(z_slice_labels)\n",
    "                z_list.append(z_slice_image)\n",
    "                progress_bar.update(1)\n",
    "            # Build z-stack array\n",
    "            z_stack = np.stack(z_list)\n",
    "            z_stack_labels = np.stack(z_list_labels)\n",
    "            built_labels = True # only needs to be built once\n",
    "            t_list.append(z_stack)\n",
    "            z_list = []\n",
    "        # Build time-laspe array\n",
    "        stack = np.stack(t_list)\n",
    "        progress_bar.close()\n",
    "\n",
    "# TODO: This needs to return a layer data tuple with the 3D stacks\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'phasor_features_labels_layer': <Labels layer 'hazelnut_3D_FLIM_z63 Phasor Features Layer' at 0x2d6a9a23010>,\n",
       " 'original_mean': array([[[0.        , 0.00757576, 0.00757576, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.00757576, 0.        , 0.00378788, ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.01136364, 0.        , 0.00378788, ..., 0.00378788,\n",
       "          0.        , 0.00378788],\n",
       "         ...,\n",
       "         [0.00378788, 0.        , 0.00378788, ..., 0.00378788,\n",
       "          0.00757576, 0.00757576],\n",
       "         [0.        , 0.00378788, 0.        , ..., 0.        ,\n",
       "          0.        , 0.00378788],\n",
       "         [0.00378788, 0.        , 0.        , ..., 0.00378788,\n",
       "          0.00757576, 0.        ]]])}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_data_tuple[0][1]['metadata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 63, 512, 512)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "napari-phasors",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
